{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming**\n",
        "#### Creating a kernel that can do vector addition of two different unidimensional vectors/tensors (1D arrays)"
      ],
      "metadata": {
        "id": "5KvIidOpk63g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS-FY0A09UQQ",
        "outputId": "2530a976-b15a-43cf-eb17-f04a91ba8657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ],
      "source": [
        "import torch, os, math, gzip, pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.request import urlretrieve\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from torch import tensor\n",
        "import torchvision as tv\n",
        "import torchvision.transforms.functional as tvf\n",
        "from torchvision import io\n",
        "from torch.utils.cpp_extension import load_inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
      ],
      "metadata": {
        "id": "61ZKuMg-9Uyj"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q wurlitzer ninja"
      ],
      "metadata": {
        "id": "XLq4PhXS9VRH"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext wurlitzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQhXkca5AxMe",
        "outputId": "317d070a-5cd1-4b9e-cdda-39a5520df56d"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The wurlitzer extension is already loaded. To reload it, use:\n",
            "  %reload_ext wurlitzer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False):\n",
        "    return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                       extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name=\"inline_ext\")"
      ],
      "metadata": {
        "id": "NDT4RKEcA3XC"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "\n",
        "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
        "'''"
      ],
      "metadata": {
        "id": "2y1wzkIKA45t"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src_mine = cuda_begin + r'''\n",
        "__global__ void VecAdd_kernel(double* x,double* out, int n) {\n",
        "    int i = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if (i<n) out[i] = x[i]+x[i+n];\n",
        "}\n",
        "\n",
        "torch::Tensor VecAdd(torch::Tensor input) {\n",
        "    CHECK_INPUT(input);\n",
        "    int h = input.size(0)/2;\n",
        "    auto output = torch::empty({h}, input.options());\n",
        "    int threads = 256;\n",
        "    VecAdd_kernel<<<cdiv(h,threads), threads>>>(\n",
        "        input.data_ptr<double>(), output.data_ptr<double>(), h);\n",
        "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "    return output;\n",
        "}'''"
      ],
      "metadata": {
        "id": "81SNEIGHQzgL"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = \"torch::Tensor VecAdd(torch::Tensor input);\""
      ],
      "metadata": {
        "id": "bJQ40b2pVTm8"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor(np.random.rand(10000000))  # A 1D tensor of 10000000 random elements\n",
        "y = torch.tensor(np.random.rand(10000000))  # A 1D tensor of 10000000 random elements\n",
        "combi = torch.cat((X.flatten(), y.flatten())) # A Concatented 1D tensor of X and y. Contains 20000000 elements in total\n",
        "combi = combi.contiguous().cuda()   ## Creating a 1D flattened CUDA tensor for Kernelling"
      ],
      "metadata": {
        "id": "oCMDj8KuPPKi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_mine = load_cuda(cuda_src_mine, cpp_src, ['VecAdd'], verbose=True) #loads our cuda kernel in a module"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft6tPNAoVZPb",
        "outputId": "d4ea45dd-503e-496d-e79a-2199ae388db3"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "The input conditions for extension module inline_ext have changed. Bumping to version 9 and re-building as inline_ext_v9...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/inline_ext/build.ninja...\n",
            "Building extension module inline_ext_v9...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=inline_ext_v9 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/inline_ext/main.cpp -o main.o \n",
            "[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=inline_ext_v9 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.10/dist-packages/torch/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.10/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.10/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++17 -c /root/.cache/torch_extensions/py310_cu121/inline_ext/cuda.cu -o cuda.cuda.o \n",
            "[3/3] c++ main.o cuda.cuda.o -shared -L/usr/local/lib/python3.10/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o inline_ext_v9.so\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module inline_ext_v9...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(module_mine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEbTTW0sbBgw",
        "outputId": "d4181cd5-da1b-4037-c5f3-9e948c77a141"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'rgb_to_grayscale']"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doing Vector Addition on X and y using CUDA kernel"
      ],
      "metadata": {
        "id": "GRyJ7t6fq7kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res = module_mine.VecAdd_kernel(combi)\n",
        "h = res.shape\n",
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPjRL9oObJFY",
        "outputId": "08012796-4d09-4e5d-fe0e-d933bce8726e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.17 ms, sys: 0 ns, total: 1.17 ms\n",
            "Wall time: 1.18 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000000])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Doing Vector Addition on X and y using a Python function"
      ],
      "metadata": {
        "id": "0YLumDICrHl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def VecAdd(A,B):\n",
        "  C=[0]*len(A)\n",
        "  for i in range(len(A)):\n",
        "    C[i]=A[i]+B[i]\n",
        "  return C\n",
        "Pyres = VecAdd(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3IHvj9WO1R8",
        "outputId": "122920aa-cf88-4b7f-e4d8-425292095be4"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 14s, sys: 2.99 s, total: 1min 17s\n",
            "Wall time: 1min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def PytVecAdd(A,B):\n",
        "  return A+B\n",
        "PyTorchRes = PytVecAdd(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If6XmV3g8w36",
        "outputId": "2586645a-118d-424c-fe87-1304009af459"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21.8 ms, sys: 37.3 ms, total: 59 ms\n",
            "Wall time: 62.5 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Writing a function to check if accurate vector addition has been done over all the elements"
      ],
      "metadata": {
        "id": "cU1rr6dZrh9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def AllElemCheck(A,B,C):\n",
        "  if len(A)!=len(B) or (len(A)!=len(C)):\n",
        "    print(\"Dimension Mismatch\")\n",
        "    return False\n",
        "  else:\n",
        "    for i in range(len(A)):\n",
        "      if(A[i]+B[i]!=C[i]):\n",
        "        print(f\"A[i]+B[i]!=C[i]\")\n",
        "        return False\n",
        "  return True\n",
        "\n"
      ],
      "metadata": {
        "id": "rJdLtSSWlo24"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calling our check function to see if the data is accurate. True = Accurate/ False = Inaccurate"
      ],
      "metadata": {
        "id": "N4CrDUjjrsg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AllElemCheck(X,y,res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekPPEeIfnexb",
        "outputId": "7fa98e44-72d8-46bc-8984-84541e22df9b"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Since the result is True there correct vector addition has been implemented***"
      ],
      "metadata": {
        "id": "S-1-xoO_sBLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The CUDA kernel took 1.17 ms for computation whereas a normal pythonic function took 77 seconds (1m 17s) and a straightforwards PyTorch based method took 59ms. That is 45294x times faster than Python and 34.7x Faster than PyTorch"
      ],
      "metadata": {
        "id": "NtX3MpGU8V_l"
      }
    }
  ]
}